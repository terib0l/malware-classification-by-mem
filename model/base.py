import numpy as np
import tensorflow as tf
from xgboost import XGBClassifier
from sklearn.svm import SVC, LinearSVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from module.schema import CaseLabel

class BaseModel:
    def __init__(
        self,
        x_train,
        y_train,
        x_test,
        parse_args,
    ):
        self.x_train=x_train
        self.y_train=y_train
        self.x_test=x_test
        self.last_layer = parse_args.last_layer
        self.convolutional_model = parse_args.model
        self.classify_func = parse_args.classify
        self.problem_case = parse_args.case
        if self.problem_case == CaseLabel.BINARY:
            self.cost_sensitive = parse_args.cost_sensitive
            self.augmentation = parse_args.augmentation


    def flow_execute(self):
        # only fcn
        if self.classify_func == "fcn":
            if self.problem_case == CaseLabel.CATEGORY:
                print("""
                        FCN - Category Case
                """)
                return self.category_case_basic_flow()
            elif self.problem_case == CaseLabel.BINARY:
                print("""
                        FCN - Binary Case
                """)
                return self.binary_case_basic_flow()
            else:
                raise NotImplementedError
        # others (svm, rf, knn, j48, xgboost)
        else:
            if self.problem_case == CaseLabel.CATEGORY:
                print("""
                        Transfer+ML - Category Case
                """)
            else:
                print("""
                        Transfer+ML - Binary Case
                """)

            return self.transfer_flow()


    def choose_last_layer(self, base_model, num_classes):
        model = tf.keras.models.Sequential()
        model.add(base_model)

        if self.last_layer == "flatten":
            model.add(tf.keras.layers.Flatten())
            """とりあえず残す"""
            model.add(tf.keras.layers.Dropout(0.5))
            model.add(tf.keras.layers.Dense(64, activation='relu'))
            model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))
        elif self.last_layer == "gap":
            model.add(tf.keras.layers.GlobalAveragePooling2D())
            model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))
        else:
            raise NotImplementedError

        return model


    def choose_convolutional_model(self):
        _, h, w, d = self.x_train.shape
        if self.convolutional_model == "vgg16":
            print("""
                    VGG16
            """)
            base_model = tf.keras.applications.VGG16(
                weights='imagenet',
                include_top=False,
                input_shape=(h, w, d)
            )

        elif self.convolutional_model == "vgg19":
            print("""
                    VGG19
            """)
            base_model = tf.keras.applications.VGG19(
                weights='imagenet',
                include_top=False,
                input_shape=(h, w, d)
            )

        elif self.convolutional_model == "resnet152":
            print("""
                    ResNet152
            """)
            base_model = tf.keras.applications.ResNet152(
                weights='imagenet',
                include_top=False,
                input_shape=(h, w, d)
            )

        elif self.convolutional_model == "densenet201":
            print("""
                    DenseNet201
            """)
            base_model = tf.keras.applications.DenseNet201(
                weights='imagenet',
                include_top=False,
                input_shape=(h, w, d)
            )

        elif self.convolutional_model == "xception":
            print("""
                    Xception
            """)
            base_model = tf.keras.applications.Xception(
                weights='imagenet',
                include_top=False,
                input_shape=(h, w, d)
            )

        elif self.convolutional_model == "inception_v3":
            print("""
                    InceptionV3
            """)
            base_model = tf.keras.applications.InceptionV3(
                weights='imagenet',
                include_top=False,
                input_shape=(h, w, d)
            )

        elif self.convolutional_model == "small_mobilenet_v3":
            print("""
                    MobileNetV3 Small
            """)
            base_model = tf.keras.applications.MobileNetV3Small(
                weights='imagenet',
                include_top=False,
                input_shape=(h, w, d)
            )

        elif self.convolutional_model == "large_mobilenet_v3":
            print("""
                    MobileNetV3 Large
            """)
            base_model = tf.keras.applications.MobileNetV3Large(
                weights='imagenet',
                include_top=False,
                input_shape=(h, w, d)
            )
        elif self.convolutional_model == "efficientnet_v2":
            print("""
                    EfficentNetV2 B0
            """)
            base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(
                weights='imagenet',
                include_top=False,
                input_shape=(h, w, d)
            )
        else:
            raise Exception("No Pretrained Model")

        base_model.trainable=False

        return base_model


    def apply_cost_sensitive(self):
        """class_weight
        negative : ラベル0の数
        positive : ラベル1の数
        weight_for_0 : 1. / negative * (negative + positive)
        weight_for_1 : 1. / positive * (negative + positive)
        class_weight = {0 : weight_for_0, 1 : weight_for_1}
        """
        if self.problem_case == CaseLabel.BINARY:
            positive = np.count_nonzero(self.y_train)
            negative = len(self.y_train) - positive
            weight_for_0 = 1. / negative * (negative + positive)
            weight_for_1 = 1. / positive * (negative + positive)
            class_weight = {0: weight_for_0, 1: weight_for_1}
            print(
                "Cost-Sensitive:",
                f"\tAll         : {len(self.y_train)}",
                f"\tPositive    : {positive}",
                f"\tNegative    : {negative}",
                f"\t----------------------------",
                f"\tClass weight: {class_weight}",
                sep="\n"
            )
        elif self.problem_case == CaseLabel.CATEGORY:
            a = np.count_nonzero(self.y_train==0)
            b = np.count_nonzero(self.y_train==1)
            c = np.count_nonzero(self.y_train==2)
            d = np.count_nonzero(self.y_train==3)
            e = np.count_nonzero(self.y_train==4)
            f = np.count_nonzero(self.y_train==5)
            g = np.count_nonzero(self.y_train==6)
            h = np.count_nonzero(self.y_train==7)
            i = np.count_nonzero(self.y_train==8)
            j = np.count_nonzero(self.y_train==9)
            k = np.count_nonzero(self.y_train==10)
            abcdefghijk = len(self.y_train)
            weight_for_0 = 1. / a * abcdefghijk
            weight_for_1 = 1. / b * abcdefghijk
            weight_for_2 = 1. / c * abcdefghijk
            weight_for_3 = 1. / d * abcdefghijk
            weight_for_4 = 1. / e * abcdefghijk
            weight_for_5 = 1. / f * abcdefghijk
            weight_for_6 = 1. / g * abcdefghijk
            weight_for_7 = 1. / h * abcdefghijk
            weight_for_8 = 1. / i * abcdefghijk
            weight_for_9 = 1. / j * abcdefghijk
            weight_for_10 = 1. / k * abcdefghijk
            class_weight = {
                0: weight_for_0,
                1: weight_for_1,
                2: weight_for_2,
                3: weight_for_3,
                4: weight_for_4,
                5: weight_for_5,
                6: weight_for_6,
                7: weight_for_7,
                8: weight_for_8,
                9: weight_for_9,
                10: weight_for_10,
            }
            print(
                "Cost-Sensitive:",
                f"\tAll: {abcdefghijk}",
                f"\t0  : {a}",
                f"\t1  : {b}",
                f"\t2  : {c}",
                f"\t3  : {d}",
                f"\t4  : {e}",
                f"\t5  : {f}",
                f"\t6  : {g}",
                f"\t7  : {h}",
                f"\t8  : {i}",
                f"\t9  : {j}",
                f"\t10 : {k}",
                f"\t----------------------------",
                f"\tClass weight: {class_weight}",
                sep="\n"
            )
        else:
            raise NotImplementedError

        return class_weight


    def binary_case_basic_flow(self):
        base_model = self.choose_convolutional_model()

        model = self.choose_last_layer(base_model, 2)
        model.summary()

        model.compile(
            optimizer=tf.keras.optimizers.Adam(
                # learning_rate=1e-5,
            ),
            # optimizer = tf.keras.optimizers.RMSprop(
            #     learning_rate=1e-5,
            # ),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )

        """Relationship between augmentaion and cost-sensitive
        [augmentation]と[cost-sensitive]が両方_on_だと, [cost-sensitive]は行われず,
        [augmentation]だけ適用される.
        """
        if self.cost_sensitive and not self.augmentation:
            class_weight = self.apply_cost_sensitive()
        else:
            class_weight = {}

        model.fit(
            x=self.x_train,
            y=self.y_train,
            batch_size=32,
            epochs=20,
            callbacks=[
                tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
            ],
            verbose='auto',
            class_weight=class_weight if class_weight else None
        )
        y_pred = model.predict(self.x_test).argmax(axis=1)
        return y_pred


    def category_case_basic_flow(self):
        base_model = self.choose_convolutional_model()

        model = self.choose_last_layer(base_model, 11)
        model.summary()

        model.compile(
            optimizer=tf.keras.optimizers.Adam(
                # learning_rate=1e-5,
            ),
            # optimizer = tf.keras.optimizers.RMSprop(
            #     learning_rate=1e-5,
            # ),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )

        model.fit(
            x=self.x_train,
            y=self.y_train,
            batch_size=32,
            epochs=20,
            callbacks=[
                tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
            ],
            verbose='auto'
        )
        y_pred = model.predict(self.x_test).argmax(axis=1)
        return y_pred


    def choose_ml_classifier(self):
        if self.classify_func == "svm":
            print("""
                    SVM
            """)
            clf = SVC(
                kernel = "rbf",
                C = 10,
                # gamma = 'scale',
            )

        elif self.classify_func == "svc":
            print("""
                    SVC
            """)
            clf = LinearSVC(
                C = 10,
            )

        elif self.classify_func == "rf":
            print("""
                    RF
            """)
            clf = RandomForestClassifier(
                # n_estimators = ,
                # max_features = ,
                # max_depth = ,
                criterion="gini",
                min_samples_leaf=1,
                random_state=0,
            )

        elif self.classify_func == "knn":
            print("""
                    KNN
            """)
            clf = KNeighborsClassifier(
                # n_neighbors = ,
                # weights = ,
                # metric = ,
            )

        elif self.classify_func == "j48":
            print("""
                    J48
            """)
            clf = DecisionTreeClassifier(
                # max_features = ,
                # ccp_alpha = ,
                # max_depth = ,
                # criterion = ,
            )

        elif self.classify_func == "xgboost":
            print("""
                    XGBOOST
            """)
            clf = XGBClassifier(
                # max_depth = ,
                # n_estimators = ,
            )

        elif self.classify_func == "test":
            print("""
                    TEST
            """)
            # kernel = {linear, poly, rbf, sigmoid, precomputed}
            clf = SVC(kernel = "linear", C = 100, gamma = 0.01)

        else:
            raise Exception("No Clf Model")

        return clf


    def transfer_flow(self):
        base_model = self.choose_convolutional_model()

        bf_train = base_model.predict(self.x_train)
        bf_train = bf_train.reshape(bf_train.shape[0], -1)
        bf_test = base_model.predict(self.x_test)
        bf_test = bf_test.reshape(bf_test.shape[0], -1)
        print("\nBottleneck Features:\nbf_train: {}\nbf_test: {}\n".format(bf_train.shape, bf_test.shape))

        clf = self.choose_ml_classifier()

        clf.fit(bf_train, self.y_train)
        y_pred = clf.predict(bf_test)

        del bf_train, bf_test

        return y_pred

