import numpy as np
import tensorflow as tf
from xgboost import XGBClassifier
from sklearn.svm import SVC, LinearSVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from module.schema import PretrainedModel, ClassifyModel, CaseLabel

class BaseModel:
    def __init__(
        self,
        x_train,
        y_train,
        x_test,
        last_layer,
        convolutional_model: PretrainedModel = PretrainedModel.VGG16,
        classify_func: ClassifyModel = ClassifyModel.FCN,
        problem_case: CaseLabel = CaseLabel.CATEGORY
    ):
        self.x_train=x_train
        self.y_train=y_train
        self.x_test=x_test
        self.last_layer = last_layer
        self.convolutional_model = convolutional_model
        self.classify_func = classify_func
        self.problem_case = problem_case


    def flow_execute(self):
        # only fcn
        if self.classify_func == "fcn":
            if self.problem_case == CaseLabel.CATEGORY:
                print("""
                        FCN - Category Case
                """)
                return self.category_case_basic_flow()
            elif self.problem_case == CaseLabel.BINARY:
                print("""
                        FCN - Binary Case
                """)
                return self.binary_case_basic_flow()
            else:
                raise NotImplementedError
        # others (svm, rf, knn, j48, xgboost)
        else:
            if self.problem_case == CaseLabel.CATEGORY:
                print("""
                        Transfer+ML - Category Case
                """)
            else:
                print("""
                        Transfer+ML - Binary Case
                """)

            return self.transfer_flow()


    def choose_last_layer(self, base_model, num_classes):
        model = tf.keras.models.Sequential()
        model.add(base_model)

        if self.last_layer == "flatten":
            model.add(tf.keras.layers.Flatten())
            model.add(tf.keras.layers.Dense(64, activation='relu'))
            # model.add(tf.keras.layers.Dropout(0.5))
            model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))
        elif self.last_layer == "gap":
            model.add(tf.keras.layers.GlobalAveragePooling2D())
            model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))
        else:
            raise NotImplementedError

        return model


    def choose_convolutional_model(self):
        _, h, w, d = self.x_train.shape
        if self.convolutional_model == "vgg16":
            print("""
                    VGG16
            """)
            base_model = tf.keras.applications.VGG16(
                weights='imagenet',
                include_top=False,
                input_shape=(h, w, d)
            )

        elif self.convolutional_model == "vgg19":
            print("""
                    VGG19
            """)
            base_model = tf.keras.applications.VGG19(
                weights='imagenet',
                include_top=False,
                input_shape=(h, w, d)
            )

        elif self.convolutional_model == "resnet152":
            print("""
                    ResNet152
            """)
            base_model = tf.keras.applications.ResNet152(
                weights='imagenet',
                include_top=False,
                input_shape=(h, w, d)
            )

        elif self.convolutional_model == "densenet201":
            print("""
                    DenseNet201
            """)
            base_model = tf.keras.applications.DenseNet201(
                weights='imagenet',
                include_top=False,
                input_shape=(h, w, d)
            )

        elif self.convolutional_model == "xception":
            print("""
                    Xception
            """)
            base_model = tf.keras.applications.Xception(
                weights='imagenet',
                include_top=False,
                input_shape=(h, w, d)
            )

        elif self.convolutional_model == "inception_v3":
            print("""
                    InceptionV3
            """)
            base_model = tf.keras.applications.InceptionV3(
                weights='imagenet',
                include_top=False,
                input_shape=(h, w, d)
            )

        elif self.convolutional_model == "small_mobilenet_v3":
            print("""
                    MobileNetV3 Small
            """)
            base_model = tf.keras.applications.MobileNetV3Small(
                weights='imagenet',
                include_top=False,
                input_shape=(h, w, d)
            )

        elif self.convolutional_model == "large_mobilenet_v3":
            print("""
                    MobileNetV3 Large
            """)
            base_model = tf.keras.applications.MobileNetV3Large(
                weights='imagenet',
                include_top=False,
                input_shape=(h, w, d)
            )
        elif self.convolutional_model == "efficientnet_v2":
            print("""
                    EfficentNetV2 B0
            """)
            base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(
                weights='imagenet',
                include_top=False,
                input_shape=(h, w, d)
            )
        else:
            raise Exception("No Pretrained Model")

        base_model.trainable=False

        return base_model


    def binary_case_basic_flow(self):
        base_model = self.choose_convolutional_model()

        model = self.choose_last_layer(base_model, 2)
        model.summary()

        model.compile(
            optimizer=tf.keras.optimizers.Adam(
                learning_rate=1e-5,
            ),
            # optimizer = tf.keras.optimizers.RMSprop(
            #     learning_rate=1e-5,
            # ),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )

        """class_weight
        negative : ラベル0の数
        positive : ラベル1の数
        weight_for_0 : 1. / negative * (negative + positive)
        weight_for_1 : 1. / positive * (negative + positive)
        class_weight = {0 : weight_for_0, 1 : weight_for_1}
        """
        positive = np.count_nonzero(self.y_train)
        negative = len(self.y_train) - positive
        print(len(self.y_train), negative, positive)
        weight_for_0 = 1. / negative * (negative + positive)
        weight_for_1 = 1. / positive * (negative + positive)
        print(weight_for_0, weight_for_1)
        class_weight = {0: weight_for_0, 1: weight_for_1}
        print(class_weight)

        model.fit(
            x=self.x_train,
            y=self.y_train,
            batch_size=32,
            epochs=15,
            callbacks=[
                tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
            ],
            verbose='auto',
            class_weight=class_weight
        )
        y_pred = model.predict(self.x_test).argmax(axis=1)
        return y_pred


    def category_case_basic_flow(self):
        base_model = self.choose_convolutional_model()

        model = self.choose_last_layer(base_model, 11)
        model.summary()

        model.compile(
            optimizer=tf.keras.optimizers.Adam(
                learning_rate=1e-5,
            ),
            # optimizer = tf.keras.optimizers.RMSprop(
            #     learning_rate=1e-5,
            # ),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )

        model.fit(
            x=self.x_train,
            y=self.y_train,
            batch_size=32,
            epochs=15,
            callbacks=[
                tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
            ],
            verbose='auto'
        )
        y_pred = model.predict(self.x_test).argmax(axis=1)
        return y_pred


    def choose_ml_classifier(self):
        if self.classify_func == "svm":
            print("""
                    SVM
            """)
            clf = SVC(
                kernel = "rbf",
                # C = 10,
                # gamma = 'scale',
            )

        elif self.classify_func == "svc":
            print("""
                    SVC
            """)
            clf = LinearSVC()

        elif self.classify_func == "rf":
            print("""
                    RF
            """)
            clf = RandomForestClassifier(
                # n_estimators = ,
                # max_features = ,
                # max_depth = ,
                criterion="gini",
                min_samples_leaf=1,
                random_state=0,
            )

        elif self.classify_func == "knn":
            print("""
                    KNN
            """)
            clf = KNeighborsClassifier(
                # n_neighbors = ,
                # weights = ,
                # metric = ,
            )

        elif self.classify_func == "j48":
            print("""
                    J48
            """)
            clf = DecisionTreeClassifier(
                # max_features = ,
                # ccp_alpha = ,
                # max_depth = ,
                # criterion = ,
            )

        elif self.classify_func == "xgboost":
            print("""
                    XGBOOST
            """)
            clf = XGBClassifier(
                # max_depth = ,
                # n_estimators = ,
            )

        elif self.classify_func == "test":
            print("""
                    TEST
            """)
            # kernel = {linear, poly, rbf, sigmoid, precomputed}
            clf = SVC(kernel = "linear", C = 100, gamma = 0.01)

        else:
            raise Exception("No Clf Model")

        return clf


    def transfer_flow(self):
        base_model = self.choose_convolutional_model()

        bf_train = base_model.predict(self.x_train)
        bf_train = bf_train.reshape(bf_train.shape[0], -1)
        bf_test = base_model.predict(self.x_test)
        bf_test = bf_test.reshape(bf_test.shape[0], -1)
        print("\nBottleneck Features:\nbf_train: {}\nbf_test: {}\n".format(bf_train.shape, bf_test.shape))

        clf = self.choose_ml_classifier()

        clf.fit(bf_train, self.y_train)
        y_pred = clf.predict(bf_test)

        del bf_train, bf_test

        return y_pred

