import tensorflow as tf
from model.basic import BasicModel


class FineTuning(BasicModel):
    def binary_case_basic_flow(self):
        base_model = self.choose_convolutional_model()

        # In addition to implement Fine-tuning
        base_model.trainable = True
        for i, layer in enumerate(base_model.layers):
            if i < 15: # 4, 7, 11, 15
                layer.trainable = False
        for i, layer in enumerate(base_model.layers):
            print(layer.name, layer.trainable)

        model = tf.keras.models.Sequential()
        model.add(base_model)
        model.add(tf.keras.layers.Flatten())
        model.add(tf.keras.layers.Dense(64, activation='relu'))
        model.add(tf.keras.layers.Dropout(0.5))
        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))
        model.summary()

        model.compile(
            # optimizer='adam',
            optimizer = tf.keras.optimizers.RMSprop(
                learning_rate=1e-5,
                # learning_rate=0.001, rho=0.9, epsilon=None, decay=0.0
            ),
            loss='binary_crossentropy',
            metrics=[
                tf.keras.metrics.BinaryAccuracy(name='accuracy'),
                tf.keras.metrics.Precision(name='precision'),
                tf.keras.metrics.Recall(name='recall'),
            ]
        )

        model.fit(
            x=self.x_train,
            y=self.y_train,
            batch_size=32,
            epochs=10,
            callbacks=[
                tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
            ],
            verbose='auto'
        )

        return model


    def category_case_basic_flow(self):
        base_model = self.choose_convolutional_model()

        # In addition to implement Fine-tuning
        base_model.trainable = True
        for i, layer in enumerate(base_model.layers):
            if i < 15: # 4, 7, 11, 15
                layer.trainable = False
        for i, layer in enumerate(base_model.layers):
            print(layer.name, layer.trainable)

        model = tf.keras.models.Sequential()
        model.add(base_model)
        model.add(tf.keras.layers.Flatten())
        model.add(tf.keras.layers.Dense(64, activation='relu'))
        model.add(tf.keras.layers.Dropout(0.5))
        model.add(tf.keras.layers.Dense(11, activation='softmax'))
        model.summary()

        model.compile(
            # optimizer='adam',
            optimizer = tf.keras.optimizers.RMSprop(
                learning_rate=1e-5,
                # learning_rate=0.001, rho=0.9, epsilon=None, decay=0.0
            ),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )

        model.fit(
            x=self.x_train,
            y=self.y_train,
            batch_size=32,
            epochs=50,
            callbacks=[
                tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
            ],
            verbose='auto'
        )
        y_pred = model.predict(self.x_test).argmax(axis=1)

        return y_pred

