import numpy as np
import tensorflow as tf
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input, Conv2D, multiply, LocallyConnected2D, Lambda, BatchNormalization
from tensorflow.keras.models import Model
from model.basic import BasicModel
from module.schema import CaseLabel


# link: https://stackoverflow.com/questions/65598647/dynamic-spatial-convolution-is-not-supported-on-tpu
def dynamic_spatial_module(conv_base, problem_case: str):
    """
    Dynamic Spatial Attention
    """
    input_shape = (256, 256, 3)
    in_lay = Input(input_shape)

    pt_features = conv_base(in_lay)
    bn_features = BatchNormalization()(pt_features)
    # here we do an attention mechanism to turn pixels in the GAP on an off
    attn_layer = Conv2D(64, kernel_size = (1,1), padding = 'same', activation = 'relu')(bn_features)
    attn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)
    attn_layer = LocallyConnected2D(1, kernel_size = (1,1), padding = 'valid', activation = 'sigmoid')(attn_layer)
    # fan it out to all of the channels
    pt_depth = conv_base.get_output_shape_at(0)[-1]
    up_c2_w = np.ones((1, 1, 1, pt_depth))
    up_c2 = Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', 
                activation = 'linear', use_bias = False, weights = [up_c2_w])
    up_c2.trainable = False
    attn_layer = up_c2(attn_layer)

    mask_features = multiply([attn_layer, bn_features])
    gap_features = GlobalAveragePooling2D()(mask_features)
    gap_mask = GlobalAveragePooling2D()(attn_layer)
    # to account for missing values from the attention model
    gap = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])
    gap_dr = Dropout(0.5)(gap)

    """
    Fully connected layer
    """
    fcn_in = Dense(1024, activation = 'elu')(gap_dr)
    # fcn_in = Dense(64, activation = 'elu')(gap_dr)  # 32, 64, 128, 256, 512, 1024
    dr_steps = Dropout(0.25)(fcn_in)
    if problem_case == CaseLabel.BINARY:
        out_layer = Dense(1, activation = 'sigmoid')(dr_steps)
    elif problem_case == CaseLabel.CATEGORY:
        out_layer = Dense(11, activation = 'softmax')(dr_steps)
    else:
        raise NotImplementedError

    model = Model(inputs = [in_lay], outputs = [out_layer])
    return model


class DynamicSpatialAttention(BasicModel):
    def binary_case_basic_flow(self):
        conv_base = self.choose_convolutional_model()

        model = dynamic_spatial_module(conv_base, self.problem_case)
        model.summary()

        model.compile(
            # optimizer='adam',
            optimizer = tf.keras.optimizers.RMSprop(
                lr=0.001, rho=0.9, epsilon=None, decay=0.0
                # lr=1e-4, rho=0.9, epsilon=None, decay=0.0
            ),
            loss='binary_crossentropy',
            metrics=[
                tf.keras.metrics.BinaryAccuracy(name='accuracy'),
                tf.keras.metrics.Precision(name='precision'),
                tf.keras.metrics.Recall(name='recall'),
            ]
        )

        model.fit(
            x=self.x_train,
            y=self.y_train,
            batch_size=32,
            epochs=50,
            callbacks=[
                tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
            ],
            verbose='auto'
        )

        return model


    def category_case_basic_flow(self):
        conv_base = self.choose_convolutional_model()

        model = dynamic_spatial_module(conv_base, self.problem_case)
        model.summary()

        model.compile(
            # optimizer='adam',
            optimizer = tf.keras.optimizers.RMSprop(
                lr=0.001, rho=0.9, epsilon=None, decay=0.0
                # lr=1e-4, rho=0.9, epsilon=None, decay=0.0
            ),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )

        model.fit(
            x=self.x_train,
            y=self.y_train,
            batch_size=32,
            epochs=50,
            callbacks=[
                tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
            ],
            verbose='auto'
        )
        y_pred = model.predict(self.x_test).argmax(axis=1)

        return y_pred


    def transfer_flow(self):
        conv_base = self.choose_convolutional_model()

        model = dynamic_spatial_module(conv_base, self.problem_case)
        model.summary()

        # Pre trained
        if self.problem_case == CaseLabel.BINARY:
            model.compile(
                optimizer='adam',
                loss='binary_crossentropy',
                metrics=[
                    tf.keras.metrics.BinaryAccuracy(name='accuracy'),
                    tf.keras.metrics.Precision(name='precision'),
                    tf.keras.metrics.Recall(name='recall'),
                ]
            )

            model.fit(
                x=self.x_train,
                y=self.y_train,
                batch_size=32,
                epochs=50,
                callbacks=[
                    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
                ],
                verbose='auto'
            )
        elif self.problem_case == CaseLabel.CATEGORY:
            model.compile(
                optimizer='adam',
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy']
            )

            model.fit(
                x=self.x_train,
                y=self.y_train,
                batch_size=32,
                epochs=50,
                callbacks=[
                    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
                ],
                verbose='auto'
            )
        else:
            raise NotImplementedError
    
        base_model = Model(model.input, model.layers[-5].output)
        base_model.summary()

        bf_train = base_model.predict(self.x_train)
        bf_train = bf_train.reshape(bf_train.shape[0], -1)
        bf_test = base_model.predict(self.x_test)
        bf_test = bf_test.reshape(bf_test.shape[0], -1)
        print("\nBottleneck Features:\nbf_train: {}\nbf_test: {}\n".format(bf_train.shape, bf_test.shape))

        del base_model
        return bf_train, bf_test

