import tensorflow as tf
from xgboost import XGBClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from module.schema import PretrainedModel, ClassifyModel, CaseLabel

class PlainModel:
    def __init__(
        self,
        x_train,
        y_train,
        x_test,
        convolutional_model: PretrainedModel = PretrainedModel.VGG16,
        classify_func: ClassifyModel = ClassifyModel.FCN,
        problem_case: CaseLabel = CaseLabel.CATEGORY
    ):
        self.x_train=x_train
        self.y_train=y_train
        self.x_test=x_test
        self.convolutional_model = convolutional_model
        self.classify_func = classify_func
        self.problem_case = problem_case


    def flow_execute(self):
        if self.classify_func == "fcn":
            if self.problem_case == CaseLabel.CATEGORY:
                print("""
                        FCN - Category Case
                """)
                return self.category_case_basic_flow()
            elif self.problem_case == CaseLabel.BINARY:
                print("""
                        FCN - Binary Case
                """)
                return self.binary_case_basic_flow()
            else:
                raise NotImplementedError
        else:
            if self.problem_case == CaseLabel.CATEGORY:
                print("""
                        Transfer+ML - Category Case
                """)
            else:
                print("""
                        Transfer+ML - Binary Case
                """)

            return self.transfer_flow()


    def choose_convolutional_model(self):
        if self.convolutional_model == "vgg16":
            base_model = tf.keras.applications.VGG16(
                weights='imagenet',
                include_top=False,
                input_shape=(256, 256, 3)
            )

        elif self.convolutional_model == "vgg19":
            base_model = tf.keras.applications.VGG19(
                weights='imagenet',
                include_top=False,
                input_shape=(256, 256, 3)
            )

        elif self.convolutional_model == "resnet50":
            base_model = tf.keras.applications.ResNet50(
                weights='imagenet',
                include_top=False,
                input_shape=(256, 256, 3)
            )

        elif self.convolutional_model == "xception":
            base_model = tf.keras.applications.Xception(
                weights='imagenet',
                include_top=False,
                input_shape=(256, 256, 3)
            )

        elif self.convolutional_model == "inception_v3":
            base_model = tf.keras.applications.InceptionV3(
                weights='imagenet',
                include_top=False,
                input_shape=(256, 256, 3)
            )

        elif self.convolutional_model == "mobilenet_v3":
            base_model = tf.keras.applications.MobileNetV3Small(
            # base_model = tf.keras.applications.MobileNetV3Large(
                weights='imagenet',
                include_top=False,
                input_shape=(256, 256, 3)
            )

        else:
            raise Exception("No Pretrained Model")

        base_model.trainable=False

        return base_model


    def binary_case_basic_flow(self):
        base_model = self.choose_convolutional_model()

        model = tf.keras.models.Sequential()
        model.add(base_model)
        model.add(tf.keras.layers.Flatten())
        model.add(tf.keras.layers.Dense(64, activation='relu'))
        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))
        model.summary()

        model.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=[
                tf.keras.metrics.BinaryAccuracy(name='accuracy'),
                tf.keras.metrics.Precision(name='precision'),
                tf.keras.metrics.Recall(name='recall'),
            ]
        )

        model.fit(
            x=self.x_train,
            y=self.y_train,
            batch_size=32,
            epochs=50,
            callbacks=[
                tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
            ],
            verbose='auto'
        )

        return model


    def category_case_basic_flow(self):
        base_model = self.choose_convolutional_model()

        model = tf.keras.models.Sequential()
        model.add(base_model)
        model.add(tf.keras.layers.Flatten())
        model.add(tf.keras.layers.Dense(64, activation='relu'))
        model.add(tf.keras.layers.Dense(11, activation='softmax'))
        model.summary()

        model.compile(
            optimizer='adam',
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )

        model.fit(
            x=self.x_train,
            y=self.y_train,
            batch_size=32,
            epochs=50,
            callbacks=[
                tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
            ],
            verbose='auto'
        )
        y_pred = model.predict(self.x_test).argmax(axis=1)

        return y_pred


    def choose_ml_classifier(self, bf_train):
        _scoring = "accuracy"
        _verbose = 4
        _cv = 3

        if self.classify_func == "svm":
            grid = GridSearchCV(
                estimator=SVC(),
                param_grid = {
                    "C": [10, 100, 1000],
                    "gamma": [0.01, 0.001, 0.0001]
                },
                cv=_cv,
                scoring=_scoring,
                verbose=_verbose
            )
            grid.fit(bf_train, self.y_train)
            print(grid.best_params_)
            
            clf = SVC(
                kernel = "rbf",
                C = grid.best_params_["C"],
                gamma = grid.best_params_["gamma"],
            )

        elif self.classify_func == "rf":
            grid = GridSearchCV(
                estimator=RandomForestClassifier(),
                param_grid = {
                    # "n_estimators": [10, 20, 30, 50, 100, 300],
                    "n_estimators": [10, 30, 50, 100],
                    "max_features": ('sqrt', 'log2', 'auto'),
                    "max_depth": (10, 20, 30, 40, 50),
                },
                cv=_cv,
                scoring=_scoring,
                verbose=_verbose
            )
            grid.fit(bf_train, self.y_train)
            print(grid.best_params_)

            clf = RandomForestClassifier(
                n_estimators = grid.best_params_["n_estimators"],
                max_features = grid.best_params_["max_features"],
                max_depth = grid.best_params_["max_depth"],
                criterion="gini",
                min_samples_leaf=1,
                random_state=0,
            )

        elif self.classify_func == "knn":
            grid = GridSearchCV(
                estimator=KNeighborsClassifier(),
                param_grid = {
                    "n_neighbors": [3, 5, 11, 19, 25, 30],
                    "weights": ['uniform', 'distance'],
                    "metric": ['euclidean', 'manhattan'],
                },
                cv=_cv,
                scoring=_scoring,
                verbose=_verbose
            )
            grid.fit(bf_train, self.y_train)
            print(grid.best_params_)

            clf = KNeighborsClassifier(
                n_neighbors = grid.best_params_["n_neighbors"],
                weights = grid.best_params_["weights"],
                metric = grid.best_params_["metric"],
            )

        elif self.classify_func == "j48":
            grid = GridSearchCV(
                estimator=DecisionTreeClassifier(random_state=1024),
                param_grid = {
                    'max_features': ['auto', 'sqrt', 'log2'],
                    'ccp_alpha': [0.1, 0.01, 0.001],
                    'max_depth' : [5, 6, 7, 8, 9],
                    'criterion' :['gini', 'entropy']
                },
                cv=_cv,
                scoring=_scoring,
                verbose=_verbose
            )
            grid.fit(bf_train, self.y_train)
            print(grid.best_params_)

            clf = DecisionTreeClassifier(
                max_features = grid.best_params_["max_features"],
                ccp_alpha = grid.best_params_["ccp_alpha"],
                max_depth = grid.best_params_["max_depth"],
                criterion = grid.best_params_["criterion"],
            )

        elif self.classify_func == "xgboost":
            grid = GridSearchCV(
                estimator=XGBClassifier(),
                param_grid = {
                    "max_depth": [2, 4, 6],
                    "n_estimators": [10, 30, 50, 100],
                },
                cv=_cv,
                scoring=_scoring,
                verbose=_verbose
            )
            grid.fit(bf_train, self.y_train)
            print(grid.best_params_)

            clf = XGBClassifier(
                max_depth = grid.best_params_["max_depth"],
                n_estimators = grid.best_params_["n_estimators"],
            )

        elif self.classify_func == "test":
            grid = None

            clf = SVC(
                # kernel = {linear, poly, rbf, sigmoid, precomputed}
                kernel = "linear",
                C = 100,
                gamma = 0.01,
            )
        else:
            raise Exception("No Clf Model")

        del grid
        return clf


    def transfer_flow(self):
        base_model = self.choose_convolutional_model()

        bf_train = base_model.predict(self.x_train)
        bf_train = bf_train.reshape(bf_train.shape[0], -1)
        bf_test = base_model.predict(self.x_test)
        bf_test = bf_test.reshape(bf_test.shape[0], -1)
        print("\nBottleneck Features:\nbf_train: {}\nbf_test: {}\n".format(bf_train.shape, bf_test.shape))

        clf = self.choose_ml_classifier(bf_train)

        clf.fit(bf_train, self.y_train)
        y_pred = clf.predict(bf_test)

        del bf_train, bf_test

        return y_pred

