import tensorflow as tf


# VGG16
# base_model = tf.keras.applications.VGG16(
#         include_top=False, input_shape=(300,300,3), weights="imagenet"
# )
# x = tf.keras.layers.GlobalAveragePooling2D()(base_model.layers[-1].output)
# x = tf.keras.layers.Dense(2, activation="softmax")(x)
# model = tf.keras.models.Model(base_model.inputs, x)
# for i, layer in enumerate(model.layers):
#     if i==0:
#         input = layer.input
#         x = input
#     else:
#         if "conv" in layer.name:
#             layer.activation = tf.keras.activations.linear
#             x = layer(x)
#             x = tf.keras.layers.BatchNormalization()(x)
#             x = tf.keras.layers.Activation("relu")(x)
#         else:
#             x = layer(x)
# model = tf.keras.models.Model(input, x)
# model.summary()
# --------------------------------------
# Total params: 14,732,610
# Trainable params: 14,724,162
# Non-trainable params: 8,448


# base_model = tf.keras.applications.DenseNet121(
#     weights="imagenet",
#     include_top=False,
#     input_shape=(300,300,3),
# )
# model = tf.keras.models.Sequential()
# model.add(base_model)
# model.add(tf.keras.layers.Flatten())
# model.add(tf.keras.layers.Dense(1024, activation='relu'))
# model.add(tf.keras.layers.BatchNormalization())
# model.add(tf.keras.layers.Dropout(0.3))
# model.add(tf.keras.layers.Dense(512, activation='relu'))
# model.add(tf.keras.layers.BatchNormalization())
# model.add(tf.keras.layers.Dropout(0.2))
# model.add(tf.keras.layers.Dense(11, activation='softmax'))
# model.summary()
# --------------------------------------
# Total params: 92,509,771
# Trainable params: 92,423,051
# Non-trainable params: 86,720
