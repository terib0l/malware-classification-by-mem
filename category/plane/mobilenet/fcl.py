import sys
sys.path.append("../../")
from lib import output_metrix_from_matrix

import glob
import numpy as np
import tensorflow as tf
from PIL import Image
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split

"""
Dataset
"""
train_dir = '/content/4096/300/TRAIN/'
test_dir = '/content/4096/300/TEST/'

labels = ["Adposhel", "Allaple", "Amonetize", "AutoRun", "BrowseFox", "Dinwod", "InstallCore", "MultiPlug", "Other", "VBA", "Vilsel"]
labels_num = len(labels)

temp_x = []
temp_y = []

for class_num, label in enumerate(labels):
    image_dir = train_dir + label
    files = glob.glob(image_dir + "/*.png")

    # 写真を順番に取得
    for f in files:
        image = Image.open(f)
        image = image.convert("RGB")
        image = image.resize(size=(256, 256))

        data = np.asarray(image)

        data = tf.keras.applications.mobilenet_v3.preprocess_input(data)

        temp_x.append(data)
        temp_y.append(class_num)

for class_num, label in enumerate(labels):
    image_dir = test_dir + label
    files = glob.glob(image_dir + "/*.png")

    # 写真を順番に取得
    for f in files:
        image = Image.open(f)
        image = image.convert("RGB")
        image = image.resize(size=(256, 256))

        data = np.asarray(image)

        data = tf.keras.applications.mobilenet_v3.preprocess_input(data)

        temp_x.append(data)
        temp_y.append(class_num)

temp_x = np.array(temp_x) / 255
temp_y = np.array(temp_y)
print(temp_x.shape)
print(temp_y.shape)

x_train, x_test, y_train, y_test = train_test_split(temp_x, temp_y, test_size=0.2, shuffle=True)
print(x_train.shape, y_train.shape)
print(x_test.shape, y_test.shape)

"""
Model
"""
base_model = tf.keras.applications.vgg19.VGG19(
    weights='imagenet',
    include_top=False,
    input_shape=(256, 256, 3)
)
base_model.trainable=False

model = tf.keras.models.Sequential()
model.add(base_model)
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(64, activation='relu'))
# model.add(tf.keras.layers.Dense(1024, activation='relu'))
# model.add(tf.keras.layers.Dense(1024, activation='relu'))
model.add(tf.keras.layers.Dense(11, activation='softmax'))
model.summary()

"""
Learning
"""
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    # loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=['accuracy']
)

model.fit(
    x=x_train,
    y=y_train,
    batch_size=32,
    epochs=10,
    verbose='auto'
)

"""
Prediction
"""
y_pred = model.predict(x_test).argmax(axis=1)

matrix = confusion_matrix(y_test, y_pred)
output_metrix_from_matrix(matrix=matrix, labels_num=labels_num)
