import glob
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from module.schema import CaseLabel


BINARY_LABELS = ["Malware", "Benign"]
CATEGORY_LABELS = [
    "Adposhel", "Allaple", "Amonetize", "AutoRun",
    "BrowseFox", "Dinwod", "InstallCore", "MultiPlug",
    "Other", "VBA", "Vilsel"
]
UNKNOWN_MALWARE_LABELS = [
    ["MultiPlug", "VBA", "Vilsel"],
    ["BrowseFox", "Dinwod", "InstallCore"],
    ["Adposhel", "Allaple", "Amonetize"]
]

class DumpwarePreparation:
    def __init__(
            self,
            data_dir: list = [
                '/content/4096/300/TRAIN/',
                '/content/4096/300/TEST/'
            ],
            case_label = CaseLabel.CATEGORY,
            model_name = "vgg16"
        ):
        self.data_dir = data_dir
        if case_label == CaseLabel.CATEGORY:
            self.labels_num = 11
        elif case_label == CaseLabel.BINARY:
            self.labels_num = 2
        self.model_name = model_name


    def preprocess_func(self):
        if self.model_name == "vgg16":
            return tf.keras.applications.vgg16.preprocess_input
        elif self.model_name == "vgg19":
            return tf.keras.applications.vgg19.preprocess_input
        elif self.model_name == "resnet152":
            return tf.keras.applications.resnet50.preprocess_input
        elif self.model_name == "densenet201":
            return tf.keras.applications.densenet.preprocess_input
        elif self.model_name == "xception":
            return tf.keras.applications.xception.preprocess_input
        elif self.model_name == "inception_v3":
            return tf.keras.applications.inception_v3.preprocess_input
        elif "mobilenet_v3" in self.model_name:
            return tf.keras.applications.mobilenet_v3.preprocess_input
        elif self.model_name == "efficientnet_v2":
            return tf.keras.applications.efficientnet_v2.preprocess_input

        return lambda x: x
            

    def prepare_dumpware10_for_category(self):
        temp_x = []
        temp_y = []

        for dir_path in self.data_dir:
            for label_num, label in enumerate(CATEGORY_LABELS):
                label_dir_path = dir_path + label
                png_paths = glob.glob(label_dir_path + "/*.png")

                for png_path in png_paths:
                    png = tf.keras.preprocessing.image.load_img(
                        path=png_path,
                        color_mode='rgb',
                        # target_size=(256, 256),
                        interpolation='bicubic'
                    )
                    png = tf.keras.preprocessing.image.img_to_array(png)
                    png = self.preprocess_func()(png)

                    temp_x.append(png)
                    temp_y.append(label_num)

        temp_x = np.array(temp_x) / 255
        temp_y = np.array(temp_y)

        return train_test_split(temp_x, temp_y, test_size=0.2, shuffle=True)


    def prepare_dumpware10_for_binary(self, fold: int, augmentation: bool = False):
        temp_mx = []
        temp_my = []
        temp_bx = []
        temp_by = []
        temp_ux = []
        temp_uy = []
        UNKNOWS = UNKNOWN_MALWARE_LABELS[fold-1]

        for dir_path in self.data_dir:
            for label in CATEGORY_LABELS:
                label_dir_path = dir_path + label
                png_paths = glob.glob(label_dir_path + "/*.png")

                for png_path in png_paths:
                    png = tf.keras.preprocessing.image.load_img(
                        path=png_path,
                        color_mode='rgb',
                        # target_size=(256, 256),
                        interpolation='bicubic'
                    )
                    png = tf.keras.preprocessing.image.img_to_array(png)
                    png = self.preprocess_func()(png)

                    if label == "Other":
                        temp_bx.append(png)
                        temp_by.append(0)
                    elif label in UNKNOWS:
                        temp_ux.append(png)
                        temp_uy.append(1)
                    else:
                        temp_mx.append(png)
                        temp_my.append(1)

        temp_bx = np.array(temp_bx) / 255
        temp_by = np.array(temp_by)
        temp_ux = np.array(temp_ux) / 255
        temp_uy = np.array(temp_uy)
        temp_mx = np.array(temp_mx) / 255
        temp_my = np.array(temp_my)

        train_bx, test_bx, train_by, test_by = \
        train_test_split(
            temp_bx, temp_by,
            train_size=(len(temp_my)/3686),
            test_size=(len(temp_uy)/3686),
            shuffle=True
        )
        del temp_bx, temp_by

        # Here, Augmentation-Part
        if augmentation:
            print("\n", "#"*30)
            train_gen = tf.keras.preprocessing.image.ImageDataGenerator()
            generator = train_gen.flow(x=train_bx, batch_size=1)
            range_num = len(temp_mx) - len(train_bx)
            for _ in range(range_num):
                batches = next(generator)
                train_bx = np.concatenate([train_bx, batches])
                train_by = np.concatenate([train_by, np.array([0])])
            del generator, train_gen
            print("#"*30, "\n")

        return np.concatenate([train_bx, temp_mx]), np.concatenate([test_bx, temp_ux]), \
                np.concatenate([train_by, temp_my]), np.concatenate([test_by, temp_uy])


def print_dataset_contents(x_train, x_test, y_train, y_test):
    # count train datas
    positive = np.count_nonzero(y_train)
    negative = len(y_train) - positive
    print(
        "train:",
        x_train.shape,
        y_train.shape,
        f"Benign: {negative}",
        f"Malware: {positive}",
        sep='\n'
    )

    # count test datas
    positive = np.count_nonzero(y_test)
    negative = len(y_test) - positive
    print(
        "train:",
        x_test.shape,
        y_test.shape,
        f"Benign: {negative}",
        f"Malware: {positive}",
        sep='\n'
    )

    del positive, negative


def dataset_operation(parse_args) -> tuple:
    dataset = DumpwarePreparation(
        case_label=parse_args.case,
        model_name=parse_args.model
    )

    # Handle the input size
    if parse_args.size == 224:
        dataset.data_dir = [
            '/content/4096/224/TRAIN/',
            '/content/4096/224/TEST/'
        ]

    # Handle how to distribute datas
    if parse_args.case == CaseLabel.BINARY:
        if parse_args.addition == "augmentation":
            x_train, x_test, y_train, y_test = \
                dataset.prepare_dumpware10_for_binary(parse_args.fold, True)
        else:
            x_train, x_test, y_train, y_test = \
                dataset.prepare_dumpware10_for_binary(parse_args.fold)
    else:  # parse_args.case == CaseLabel.CATEGORY:
        x_train, x_test, y_train, y_test = dataset.prepare_dumpware10_for_category()

    print_dataset_contents(x_train, x_test, y_train, y_test)

    return x_train, x_test, y_train, y_test

